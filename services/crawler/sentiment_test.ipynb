{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Union\n",
    "from attr import dataclass\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = 'Sen. @RandPaul: \\\"I think the Bidens are as corrupt as the day is long. No young man who is the son of a politician gets $50,000 a month who has no experience, working for a Ukrainian oligarch.\\\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(test_sentence)\n",
    "subtokens = [token for token in doc] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['compound:Sen.', 'ROOT:@RandPaul', 'punct::', 'punct:\"', 'nsubj:I', 'ROOT:think', 'det:the', 'nsubj:Bidens', 'ccomp:are', 'advmod:as', 'acomp:corrupt', 'mark:as', 'det:the', 'nsubj:day', 'advcl:is', 'acomp:long', 'punct:.', 'det:No', 'amod:young', 'nsubj:man', 'nsubj:who', 'relcl:is', 'det:the', 'attr:son', 'prep:of', 'det:a', 'pobj:politician', 'ROOT:gets', 'nmod:$', 'dobj:50,000', 'det:a', 'npadvmod:month', 'nsubj:who', 'relcl:has', 'det:no', 'dobj:experience', 'punct:,', 'advcl:working', 'prep:for', 'det:a', 'amod:Ukrainian', 'pobj:oligarch', 'punct:.', 'punct:\"']\n"
     ]
    }
   ],
   "source": [
    "print([toc.dep_ + \":\" + toc.text for toc in subtokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sen., @RandPaul, :, \", I, think, the, Bidens, are, as, corrupt, as, the, day, is, long, ., No, young, man, who, is, the, son, of, a, politician, gets, $, 50,000, a, month, who, has, no, experience, ,, working, for, a, Ukrainian, oligarch, ., \"]\n"
     ]
    }
   ],
   "source": [
    "print(subtokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(init=False)\n",
    "class AnalysisResult:\n",
    "    sentiment: float\n",
    "    subjectResults: Dict[str, float]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SentenceSubjectResult:\n",
    "    sentiment: float\n",
    "    subject: str\n",
    "    pos: str\n",
    "\n",
    "\n",
    "class SentimentAnalyzer:\n",
    "\n",
    "    def __init__(self, subjects: List[str] = None):\n",
    "        self._analyzer = SentimentIntensityAnalyzer()\n",
    "        self._nlp = spacy.load('en')\n",
    "        self._subjects = subjects\n",
    "\n",
    "    def analyze(self, statement: str) -> AnalysisResult:\n",
    "        analysis_result = AnalysisResult()\n",
    "        scores = self._analyzer.polarity_scores(statement)\n",
    "        analysis_result.sentiment = self._normalize_score(scores['compound'])\n",
    "        analysis_result.subjectResults = {}\n",
    "\n",
    "        sentences_subject_results: Dict[int, Dict[str, SentenceSubjectResult]] = {}\n",
    "        doc = self._nlp(statement)\n",
    "        for token in doc:\n",
    "            subject = self._lookup_subject(token.text)\n",
    "            if subject is None:\n",
    "                continue\n",
    "            score = self._analyzer.polarity_scores(token.sent.text)['compound']\n",
    "            adjusted_score = self._normalize_score(score)\n",
    "            subject_result = SentenceSubjectResult(sentiment=adjusted_score, subject=subject, pos=token.dep_)\n",
    "            if token.sent.start not in sentences_subject_results:\n",
    "                sentences_subject_results[token.sent.start] = {}\n",
    "            sentences_subject_results[token.sent.start][subject] = subject_result\n",
    "\n",
    "        for sentence_subject_results in sentences_subject_results.values():\n",
    "            if len(sentence_subject_results.keys()) == 0:\n",
    "                continue\n",
    "            elif len(sentence_subject_results.keys()) == 1:\n",
    "                key = list(sentence_subject_results.keys())[0]\n",
    "                analysis_result.subjectResults[sentence_subject_results[key].subject] = \\\n",
    "                    sentence_subject_results[key].sentiment\n",
    "                analysis_result.sentiment = sentence_subject_results[key].sentiment\n",
    "                continue\n",
    "            for subject in sentence_subject_results.keys():\n",
    "                subject_result = sentence_subject_results[subject]\n",
    "                if subject_result.pos == 'nsubj' or subject_result.pos == 'compound':\n",
    "                    continue\n",
    "                analysis_result.subjectResults[subject_result.subject] = subject_result.sentiment\n",
    "\n",
    "        return analysis_result\n",
    "\n",
    "    @staticmethod\n",
    "    def _normalize_score(score: float):\n",
    "        return score * 5 + 5\n",
    "\n",
    "    def _lookup_subject(self, sentence_subject: str) -> Union[str, None]:\n",
    "        if self._subjects is None:\n",
    "            return None\n",
    "\n",
    "        for subject in self._subjects:\n",
    "            subject_words = subject.split()\n",
    "            for subject_word in subject_words:\n",
    "                if sentence_subject.lower() == subject_word.lower():\n",
    "                    return subject\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentAnalyzer(['Donald Trump', 'Tammy Duckworth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalysisResult(sentiment=2.3665000000000003, subjectResults={})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.analyze(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
